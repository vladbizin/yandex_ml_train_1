{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных происходит ниже. Если она не срабатывает, самостоятельно скачайте файл `hw_final_open_data.npy` и положите его в ту же директорию, что и ноутбук."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists('hw_final_open_data.npy'), 'Please, download `hw_final_open_data.npy` and place it in the working directory'\n",
    "assert os.path.exists('hw_final_open_target.npy'), 'Please, download `hw_final_open_target.npy` and place it in the working directory'\n",
    "data = np.load('hw_final_open_data.npy', allow_pickle=False)\n",
    "target = np.load('hw_final_open_target.npy', allow_pickle=False)\n",
    "\n",
    "assert os.path.exists('hw_final_closed_data.npy'), 'Please, download `hw_final_closed_data.npy` and place it in the working directory'\n",
    "closed_data = np.load('hw_final_closed_data.npy', allow_pickle=False)\n",
    "test_x = closed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбивка на `train` и `val` аналогичная разбиваке на `train` и `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tmp_data = PCA(1).fit_transform(data)\n",
    "data_sorted = data[np.argsort(tmp_data, axis=0).flatten()]\n",
    "tmp_target = target[np.argsort(tmp_data, axis=0).flatten()]\n",
    "f = (9-np.sqrt(65))/8\n",
    "over_size = int((1-f) * tmp_data.shape[0])\n",
    "inter_size = f/(1-f)\n",
    "\n",
    "train_x_tmp, valid_x_tmp_1, train_y_tmp, valid_y_tmp_1 = data_sorted[:over_size], data_sorted[over_size:], tmp_target[:over_size], tmp_target[over_size:]\n",
    "\n",
    "train_x, valid_x_tmp_2, train_y, valid_y_tmp_2 = train_test_split(train_x_tmp, train_y_tmp, test_size = inter_size, random_state=42)\n",
    "\n",
    "valid_x, valid_y = np.vstack([valid_x_tmp_1, valid_x_tmp_2]), np.hstack([valid_y_tmp_1, valid_y_tmp_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# на корреляции можно получить то же самое\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "select_k = SelectKBest(k=3)\n",
    "select_k.fit(train_x, train_y);\n",
    "\n",
    "train_x, valid_x, test_x = select_k.transform(train_x), select_k.transform(valid_x), select_k.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на оставшиеся признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(pd.DataFrame(data).loc[:,select_k.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как будто бы признак 6 содержит только константные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(train_x[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "select_std = VarianceThreshold(1e-10)\n",
    "select_std.fit(train_x)\n",
    "\n",
    "train_x, valid_x, test_x = select_std.transform(train_x), select_std.transform(valid_x), select_std.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А из оставшихся двух второй это первый в квадрате"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(train_x[:,0]**2, train_x[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, test_x = train_x[:,0].ravel(), valid_x[:,0].ravel(), test_x[:,0].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if our `train-val` split is similair to `train-test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2)\n",
    "\n",
    "ax[0].scatter(np.hstack([train_x, valid_x]), np.ones_like(np.hstack([train_x, valid_x])), c=\"k\", label=\"train\", zorder=1, s=5)\n",
    "ax[0].scatter(test_x, np.ones_like(test_x), c=\"r\", label=\"test\", zorder=2, s=5)\n",
    "\n",
    "ax[1].scatter(train_x, np.ones_like(train_x), c=\"k\", label=\"train\", zorder=1, s=5)\n",
    "ax[1].scatter(valid_x, np.ones_like(valid_x), c=\"r\", label=\"valid\", zorder=2, s=5)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c, d):\n",
    "    return a + b * np.log(1 + np.exp(c * (x - d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(func, train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = func(train_x, *popt)\n",
    "\n",
    "m = np.mean(np.abs(y_pred-train_y))\n",
    "s = np.std(np.abs(y_pred-train_y))\n",
    "\n",
    "mask = np.abs(y_pred-train_y) < m + 3 * s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_x[mask], train_y[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refitting after outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(func, train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfomance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'train mse = %.3f ± %.3f' % (mean_squared_error(np.round(func(train_x, *popt), 2), np.round(train_y)),\n",
    "                                   np.std((np.round(func(train_x, *popt), 2) - np.round(train_y))**2)),\n",
    "    'validation mse =  %.3f ± %.3f' % (mean_squared_error(np.round(func(valid_x, *popt), 2), np.round(valid_y)),\n",
    "                                         np.std((np.round(func(valid_x, *popt), 2) - np.round(valid_y))**2)),\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting closed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.hstack([train_x, valid_x])\n",
    "train_y = np.hstack([train_y, valid_y])\n",
    "\n",
    "popt, pcov = curve_fit(func, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = func(train_x, *popt)\n",
    "\n",
    "m = np.mean(np.abs(y_pred-train_y))\n",
    "s = np.std(np.abs(y_pred-train_y))\n",
    "\n",
    "mask = np.abs(y_pred-train_y) < m + 3 * s \n",
    "\n",
    "train_x, train_y = train_x[mask], train_y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(func, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = np.round(func(test_x, *popt), 2)\n",
    "\n",
    "assert predicted_values.shape == (closed_data.shape[0], ) # predictions should be just one-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def float_list_to_comma_separated_str(_list):\n",
    "    _list = list(np.round(np.array(_list), 2))\n",
    "    return ','.join([str(x) for x in _list])\n",
    "\n",
    "submission_dict = {\n",
    "    'predictions': float_list_to_comma_separated_str(predicted_values)\n",
    "}\n",
    "with open('submission_dict_final_p01.json', 'w') as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "    \n",
    "print('File saved to `submission_dict_final_p01.npy`')\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_transformation(feature_matrix: np.ndarray):\n",
    "    pivot_feature =  -0.6647707911870174 + 9.552041008683448 * np.log(1 + np.exp(43.97277925736383 * (feature_matrix[:, 4] - -0.4847561801397369)))\n",
    "    return pivot_feature.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train_x = my_transformation(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Ridge()\n",
    "lr.fit(transformed_train_x, train_y)\n",
    "\n",
    "print(\n",
    "    f'train mse =\\t {mean_squared_error(lr.predict(transformed_train_x), train_y):.5f}',\n",
    "    f'validation mse = {mean_squared_error(lr.predict(my_transformation(valid_x)), valid_y):.5f}',\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем ваше внимание, что параметры линейной модели будут округляться до __четырех знаков после запятой__. Это не должно сильно повлиять на качество предсказаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_predictions = lr.predict(transformed_train_x)\n",
    "rounded_predictions = transformed_train_x.dot(np.round(lr.coef_, 4)) + np.round(lr.intercept_, 4)\n",
    "\n",
    "\n",
    "assert np.allclose(original_predictions, rounded_predictions, atol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры вашей модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_list = list(np.round(lr.coef_, 4))\n",
    "print(f'w = {list(np.round(lr.coef_, 4))}\\nb = {np.round(lr.intercept_, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоминаем, ваша модель не должна использовать более 15 параметров (14 весов плюс свободный член)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(w_list) + 1 <= 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сдача второй части соревнования\n",
    "Для сдачи вам достаточно отправить функцию `my_transformation` и параметры вашей модели в контест в задачу №2. Пример посылки доступен ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __________example_submission_start__________\n",
    "import numpy as np\n",
    "def my_transformation(feature_matrix: np.ndarray):\n",
    "    pivot_feature =  -0.6647707911870174 + 9.552041008683448 * np.log(1 + np.exp(43.97277925736383 * (feature_matrix[:, 4] - -0.4847561801397369)))\n",
    "    return pivot_feature.reshape(-1,1)\n",
    "\n",
    "w_submission = [1.0012]\n",
    "b_submission = -0.0063\n",
    "# __________example_submission_end__________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
